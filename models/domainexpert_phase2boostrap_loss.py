# -*- coding: utf-8 -*-
"""Domainexpert_phase2boostrap_loss

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1R3spkijxS6oA4wF-OhUflrxPfhODCZ0M

# Biblioth√®ques
"""

!pip install --upgrade pip
!pip install --upgrade transformers>=4.30.0

"""# Read data

"""

import pandas as pd
df = pd.read_csv("/content/drive/MyDrive/auchanfrance/produits_nettoyes.csv", sep=';', on_bad_lines='skip')
df.head(5)

"""# Data augmentation"""

import random
import math
import numpy as np
import pandas as pd
from tqdm.auto import tqdm
import torch
import torch.nn as nn


from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import f1_score, accuracy_score
from sklearn.utils.class_weight import compute_class_weight

# ----------------------------
# CONFIG
# ----------------------------
DATA_PATH = "/content/drive/MyDrive/auchanfrance/produits_nettoyes.csv"

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
print("Device:", DEVICE)

SEED = 42
MAX_LEN = 160
BATCH_SIZE = 4               # small because xlm-roberta-large heavy; we use grad accumulation
GRAD_ACCUM_STEPS = 8         # effective batch size = BATCH_SIZE * GRAD_ACCUM_STEPS
NUM_EPOCHS = 6
BASE_LR = 2e-5
WEIGHT_DECAY = 0.01
WARMUP_PCT = 0.05
NUM_WORKERS = 2
RARE_THRESH = 50             # seuil pour consid√©rer "rare"
PATIENCE = 3                 # early stopping patience (val F1)

# reproducibility
random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
if torch.cuda.is_available():
    torch.cuda.manual_seed_all(SEED)

# ----------------------------
# 1) Read dataset & encode labels
# ----------------------------
df = pd.read_csv(DATA_PATH, sep=';', on_bad_lines='skip')
df['description'] = df['description'].astype(str)
df['taxonomy_path'] = df['taxonomy_path'].astype(str)

texts = df['description'].tolist()
labels_raw = df['taxonomy_path'].tolist()

le = LabelEncoder()
labels = le.fit_transform(labels_raw)
num_classes = len(le.classes_)
print(f"Dataset total : {len(df)} lignes")
print(f"Nombre de labels uniques : {num_classes}")

# ----------------------------
# 2) Stratified split + dedup val/test
# ----------------------------
X_train, X_temp, y_train, y_temp = train_test_split(
    texts, labels, test_size=0.30, random_state=SEED, stratify=labels
)
X_val, X_test, y_val, y_test = train_test_split(
    X_temp, y_temp, test_size=0.50, random_state=SEED, stratify=y_temp
)

train_df = pd.DataFrame({"description": X_train, "taxonomy_path": le.inverse_transform(y_train)})
val_df   = pd.DataFrame({"description": X_val,   "taxonomy_path": le.inverse_transform(y_val)})
test_df  = pd.DataFrame({"description": X_test,  "taxonomy_path": le.inverse_transform(y_test)})

KEY = ["description", "taxonomy_path"]
val_df = val_df.drop_duplicates(subset=KEY, keep="first").reset_index(drop=True)
test_df = test_df.drop_duplicates(subset=KEY, keep="first").reset_index(drop=True)

print(f"Taille val apr√®s d√©doublonnage : {len(val_df)}")
print(f"Taille test apr√®s d√©doublonnage : {len(test_df)}")

# reconstruct lists (train kept duplicates intentionally)
X_train = train_df['description'].tolist()
y_train = le.transform(train_df['taxonomy_path'])
X_val   = val_df['description'].tolist()
y_val   = le.transform(val_df['taxonomy_path'])
X_test  = test_df['description'].tolist()
y_test  = le.transform(test_df['taxonomy_path'])

# ----------------------------
# 3) Augmentation classes rares (garder ta m√©thode)
# ----------------------------
counts = pd.Series(y_train).value_counts()
rare_classes = counts[counts < RARE_THRESH].index.tolist()
print(f"Classes rares (<{RARE_THRESH}) : {len(rare_classes)}")

def augment_texts_weighted(text, taxonomy, n_masks=2):
    # keep original + full taxonomy + masked variants
    out = [f"{text} | Category path: {taxonomy}"]
    parts = taxonomy.split(" > ")
    for _ in range(n_masks):
        if len(parts) > 1:
            idx = np.random.randint(0, len(parts))
            masked = [parts[i] if i != idx else "[MASK]" for i in range(len(parts))]
            out.append(f"{text} | Category path: {' > '.join(masked)}")
    return out

aug_texts = list(X_train)
aug_labels = list(y_train)

for txt, lbl in zip(X_train, y_train):
    if lbl in rare_classes:
        taxonomy = le.inverse_transform([lbl])[0]
        new_versions = augment_texts_weighted(txt, taxonomy, n_masks=3)
        aug_texts.extend(new_versions)
        aug_labels.extend([lbl] * len(new_versions))

X_train_aug = aug_texts
y_train_aug = aug_labels
print("Taille train apr√®s augmentation :", len(X_train_aug))

import os

# ----------------------------
# 4) Cr√©er le dossier de sortie
# ----------------------------
OUTPUT_DIR = "dataauchan"
os.makedirs(OUTPUT_DIR, exist_ok=True)

# ----------------------------
# 5) Pr√©parer les DataFrames pour sauvegarde
# ----------------------------
train_df_aug = pd.DataFrame({
    "description": X_train_aug,
    "taxonomy_path": le.inverse_transform(y_train_aug)
})

val_df_clean = pd.DataFrame({
    "description": X_val,
    "taxonomy_path": le.inverse_transform(y_val)
})

test_df_clean = pd.DataFrame({
    "description": X_test,
    "taxonomy_path": le.inverse_transform(y_test)
})

# ----------------------------
# 6) Sauvegarder au format CSV
# ----------------------------
train_path = os.path.join(OUTPUT_DIR, "train.csv")
val_path   = os.path.join(OUTPUT_DIR, "val.csv")
test_path  = os.path.join(OUTPUT_DIR, "test.csv")

train_df_aug.to_csv(train_path, index=False, sep=';')
val_df_clean.to_csv(val_path, index=False, sep=';')
test_df_clean.to_csv(test_path, index=False, sep=';')

print(f"‚úÖ Train sauvegard√© : {train_path} ({len(train_df_aug)} lignes)")
print(f"‚úÖ Val sauvegard√©   : {val_path} ({len(val_df_clean)} lignes)")
print(f"‚úÖ Test sauvegard√©  : {test_path} ({len(test_df_clean)} lignes)")

"""# ‚úÖ Train sauvegard√© : dataauchan/train.csv (110266 lignes)
# ‚úÖ Val sauvegard√©   : dataauchan/val.csv (9582 lignes)
# ‚úÖ Test sauvegard√©  : dataauchan/test.csv (9589 lignes)


"""

import shutil
import os

# Chemin local
local_folder = "dataauchan"

# Chemin sur ton Drive (adapte si n√©cessaire)
drive_folder = "/content/drive/MyDrive/dataauchan"
os.makedirs(drive_folder, exist_ok=True)

# Copier le dossier entier
shutil.copytree(local_folder, drive_folder, dirs_exist_ok=True)

print(f"‚úÖ Dossier copi√© dans Drive : {drive_folder}")

"""# phase2 : boostrap loss"""

# -*- coding: utf-8 -*-
"""
PHASE 2 ‚Äî Fine-tune Domain Expert (Bootstrap Loss + Label Smoothing + Cosine Scheduler + Progressive Unfreeze)
"""
import os
os.environ["TOKENIZERS_PARALLELISM"] = "false"

import random
import numpy as np
import pandas as pd
from tqdm.auto import tqdm
import gc
import time

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler
from transformers import (
    XLMRobertaTokenizerFast,
    XLMRobertaModel,
    AdamW
)
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import f1_score, accuracy_score, classification_report, precision_recall_fscore_support

from torch.optim.lr_scheduler import CosineAnnealingLR

# ----------------------------
# CONFIG
# ----------------------------
DATA_PATH = "/kaggle/input/produits_nettoyes.csv"
PHASE1_CKPT = "/kaggle/working/best_domain_expert_resume_ep7/best_domain_expert_xlmlarge_ep10.pth"
OUTPUT_DIR = "./best_domain_expert_phase2_bootstrap_v2"
os.makedirs(OUTPUT_DIR, exist_ok=True)

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
print("Device:", DEVICE)

SEED = 42
MAX_LEN = 200  # augment√©
BATCH_SIZE = 4
GRAD_ACCUM_STEPS = 8
NUM_EPOCHS = 3
BASE_LR = 2e-5
WEIGHT_DECAY = 0.01
NUM_WORKERS = 2
RARE_THRESH = 50
PATIENCE = 3

SAVE_NAME = os.path.join(OUTPUT_DIR, "best_domain_expert_phase2_v2.pth")
PRED_CSV = os.path.join(OUTPUT_DIR, "predictions_phase2_v2.csv")
REPORT_TXT = os.path.join(OUTPUT_DIR, "classification_report_phase2_v2.txt")


# ----------------------------
# 7) Load Phase1 checkpoint
# ----------------------------
if os.path.exists(PHASE1_CKPT):
    print("Phase1 checkpoint found, loading...")
    ckpt = torch.load(PHASE1_CKPT, map_location="cpu")
    sd = ckpt.get("model_state_dict", ckpt) if isinstance(ckpt, dict) else ckpt
    new_sd = {k.replace("module.", ""): v for k,v in sd.items()}
    model.load_state_dict(new_sd, strict=False)
    print("‚úÖ Loaded Phase1 checkpoint.")
    del ckpt, sd
    gc.collect()
    torch.cuda.empty_cache()

model = model.to(DEVICE)
try:
    model.xlm.gradient_checkpointing_enable()
    print("Gradient checkpointing ENABLED")
except:
    pass

# ----------------------------
# 8) Loss
# ----------------------------
class BootstrapSoftLoss(nn.Module):
    def __init__(self, beta=0.8, reduction="mean"):
        super().__init__()
        self.beta = beta
        self.ce = nn.CrossEntropyLoss(label_smoothing=0.1, reduction="none")
        self.reduction = reduction
    def forward(self, logits, targets):
        ce_hard = self.ce(logits, targets)
        pseudo_labels = torch.softmax(logits.detach(), dim=1)
        ce_soft = -torch.sum(pseudo_labels * torch.log_softmax(logits, dim=1), dim=1)
        loss = self.beta * ce_hard + (1.0 - self.beta) * ce_soft
        return loss.mean() if self.reduction=="mean" else loss.sum()

criterion = BootstrapSoftLoss(beta=0.8)

# ----------------------------
# 9) Optimizer + Scheduler + GradScaler
# ----------------------------
optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=BASE_LR, weight_decay=WEIGHT_DECAY)
total_steps = (len(train_loader) * NUM_EPOCHS) // max(1, GRAD_ACCUM_STEPS)
scheduler = CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS * len(train_loader))
scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE=="cuda"))

# ----------------------------
# 10) Freeze backbone 1-2 epochs
# ----------------------------
for param in model.xlm.parameters():
    param.requires_grad = False

# ----------------------------
# 11) Training loop
# ----------------------------
best_f1 = 0.0
no_improve = 0

for epoch in range(1, NUM_EPOCHS+1):
    # progressive unfreeze
    if epoch == 3:
        for param in model.xlm.parameters():
            param.requires_grad = True
        print("üì¢ XLM-R backbone UNFROZEN for fine-tuning")

    model.train()
    running_loss = 0.0
    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f"Epoch {epoch}/{NUM_EPOCHS} [Train]")
    optimizer.zero_grad()
    epoch_start = time.time()
    for step, batch in pbar:
        input_ids = batch["input_ids"].to(DEVICE)
        attention_mask = batch["attention_mask"].to(DEVICE)
        labels_b = batch["labels"].to(DEVICE)

        with torch.cuda.amp.autocast(enabled=(DEVICE=="cuda")):
            logits = model(input_ids, attention_mask)
            loss = criterion(logits, labels_b) / GRAD_ACCUM_STEPS

        scaler.scale(loss).backward()

        if (step+1) % GRAD_ACCUM_STEPS == 0 or (step+1) == len(train_loader):
            scaler.unscale_(optimizer)
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            scaler.step(optimizer)
            scaler.update()
            optimizer.zero_grad()
            scheduler.step()

        running_loss += loss.item() * GRAD_ACCUM_STEPS
        pbar.set_postfix({"avg_loss": f"{running_loss/(step+1):.4f}"})

    # Validation
    model.eval()
    all_preds, all_trues = [], []
    with torch.no_grad():
        for batch in tqdm(val_loader, desc=f"Epoch {epoch} [Val]", leave=False):
            input_ids = batch["input_ids"].to(DEVICE)
            attention_mask = batch["attention_mask"].to(DEVICE)
            labels_b = batch["labels"].to(DEVICE)
            logits = model(input_ids, attention_mask)
            _ = criterion(logits, labels_b)
            preds = torch.argmax(logits, dim=1)
            all_preds.extend(preds.cpu().numpy())
            all_trues.extend(labels_b.cpu().numpy())

    val_f1 = f1_score(all_trues, all_preds, average="macro")
    val_acc = accuracy_score(all_trues, all_preds)
    print(f"Epoch {epoch} -> ValAcc: {val_acc:.4f} | ValF1: {val_f1:.4f}")

    if val_f1 > best_f1:
        best_f1 = val_f1
        no_improve = 0
        torch.save(model.state_dict(), SAVE_NAME)
        print("üî• New best saved")
    else:
        no_improve += 1
        print(f"No improvement: {no_improve}/{PATIENCE}")
        if no_improve >= PATIENCE:
            print("Early stopping triggered")
            break

# ----------------------------
# 12) Final Evaluation
# ----------------------------
model.load_state_dict(torch.load(SAVE_NAME, map_location=DEVICE))
model.eval()

all_preds, all_trues = [], []
with torch.no_grad():
    for batch in tqdm(test_loader, desc="Test Eval"):
        input_ids = batch["input_ids"].to(DEVICE)
        attention_mask = batch["attention_mask"].to(DEVICE)
        labels_b = batch["labels"].to(DEVICE)
        logits = model(input_ids, attention_mask)
        preds = torch.argmax(logits, dim=1)
        all_preds.extend(preds.cpu().numpy())
        all_trues.extend(labels_b.cpu().numpy())

# Metrics
test_f1 = f1_score(all_trues, all_preds, average="macro")
test_acc = accuracy_score(all_trues, all_preds)
prec_macro, recall_macro, _, _ = precision_recall_fscore_support(all_trues, all_preds, average='macro')
f1_micro_val = f1_score(all_trues, all_preds, average='micro')

print(f"Test Accuracy : {test_acc:.4f}")
print(f"Test F1-macro : {test_f1:.4f}")
print(f"Precision (macro): {prec_macro:.4f}")
print(f"Recall (macro): {recall_macro:.4f}")
print(f"F1-score (micro): {f1_micro_val:.4f}")

# Classification report
report = classification_report(all_trues, all_preds, target_names=le.classes_, zero_division=0)
with open(REPORT_TXT, "w", encoding="utf-8") as f:
    f.write(report)

# Save predictions
pred_df = pd.DataFrame({
    "true_label_id": all_trues,
    "true_label_name": [le.inverse_transform([int(x)])[0] for x in all_trues],
    "pred_label_id": all_preds,
    "pred_label_name": [le.inverse_transform([int(x)])[0] for x in all_preds],
    "text": X_test[:len(all_preds)]
})
pred_df.to_csv(PRED_CSV, index=False)
print("Predictions saved ->", PRED_CSV)

"""#top k prediction"""

# ============================================================
# TOP-1 and TOP-10 ACCURACY
# ============================================================

import torch
import numpy as np
from tqdm import tqdm

model.eval()

top1_correct = 0
top10_correct = 0
total_samples = 0

with torch.no_grad():
    tbar = tqdm(test_loader, desc="Top-k Eval")
    for batch in tbar:
        input_ids = batch["input_ids"].to(DEVICE)
        attention_mask = batch["attention_mask"].to(DEVICE)
        labels = batch["labels"].to(DEVICE)

        logits = model(input_ids, attention_mask)

        # Top-1 predictions
        top1_preds = torch.argmax(logits, dim=1)

        # Top-10 predictions
        top10_preds = torch.topk(logits, k=10, dim=1).indices

        # Count Top-1 correct
        top1_correct += (top1_preds == labels).sum().item()

        # Count Top-10 correct
        top5_correct += sum(
            labels[i].item() in top10_preds[i].tolist()
            for i in range(labels.size(0))
        )

        total_samples += labels.size(0)

# Final metrics
top1_acc = top1_correct / total_samples
top10_acc = top10_correct / total_samples

print("\n========== TOP-K RESULTS ==========")
print(f"Top-1 Accuracy : {top1_acc:.4f}")
print(f"Top-5 Accuracy : {top5_acc:.4f}")

# ============================================
# Charger le best Phase2 model
# ============================================
BEST_PHASE2 = "/kaggle/input/domainexpert/best_domain_expert_phase2_v2 (10).pth"
model.load_state_dict(torch.load(BEST_PHASE2, map_location=DEVICE))
model.eval()
print("‚úÖ Best Phase2 model charg√©")

# ============================================
# Predictions Top1 + Top10 (full test set)
# ============================================
top1_preds = []
top10_preds = []

for batch in tqdm(test_loader, desc="Predictions Top1/Top10"):
    input_ids = batch["input_ids"].to(DEVICE)
    attention_mask = batch["attention_mask"].to(DEVICE)

    with torch.no_grad():
        logits = model(input_ids, attention_mask)
        probs = torch.softmax(logits, dim=-1)
        top10 = torch.topk(probs, k=10, dim=-1)

        # transformer chaque ligne du top10 en labels
        for indices in top10.indices.cpu().numpy():
            labels_top10 = le.inverse_transform(indices)
            top10_preds.append(list(labels_top10))
            top1_preds.append(labels_top10[0])

# ============================================
# Cr√©er DataFrame
# ============================================
df_test_preds = pd.DataFrame({
    "description": X_test[:len(top1_preds)],
    "true_label": le.inverse_transform(y_test[:len(top1_preds)]),
    "top1_pred": top1_preds,
    "top10_preds": top10_preds
})

# ============================================
# Sauvegarder CSV
# ============================================
OUT_CSV = "./domain_expert_phase2_top10_predictions_full.csv"
df_test_preds.to_csv(OUT_CSV, index=False)
print(f"‚úÖ CSV sauvegard√© : {OUT_CSV}")

"""# ‚úÖ Best Phase2 model charg√©
Predictions Top1/Top10:   0%|          | 0/300 [00:00<?, ?it/s]
‚úÖ CSV sauvegard√© : ./domain_expert_phase2_top10_predictions_full.csv
"""

# ============================================
# Imports
# ============================================
import torch
import numpy as np
import pandas as pd
from tqdm import tqdm

from sklearn.metrics import (
    accuracy_score,
    precision_recall_fscore_support,
    classification_report,
    confusion_matrix
)

import matplotlib.pyplot as plt
import seaborn as sns

# ============================================
# Charger le best Phase2 model
# ============================================
BEST_PHASE2 = "/kaggle/input/domainexpert/best_domain_expert_phase2_v2 (10).pth"
model.load_state_dict(torch.load(BEST_PHASE2, map_location=DEVICE))
model.eval()
print("‚úÖ Best Phase2 model charg√©")

# ============================================
# Predictions Top1 + Top10 (full test set)
# ============================================
top1_preds = []
top10_preds = []

for batch in tqdm(test_loader, desc="Predictions Top1/Top10"):
    input_ids = batch["input_ids"].to(DEVICE)
    attention_mask = batch["attention_mask"].to(DEVICE)

    with torch.no_grad():
        logits = model(input_ids, attention_mask)
        probs = torch.softmax(logits, dim=-1)
        top10 = torch.topk(probs, k=10, dim=-1)

        for indices in top10.indices.cpu().numpy():
            labels_top10 = le.inverse_transform(indices)
            top10_preds.append(list(labels_top10))
            top1_preds.append(labels_top10[0])

# ============================================
# Cr√©ation DataFrame + CSV
# ============================================
df_test_preds = pd.DataFrame({
    "description": X_test[:len(top1_preds)],
    "true_label": le.inverse_transform(y_test[:len(top1_preds)]),
    "top1_pred": top1_preds,
    "top10_preds": top10_preds
})

OUT_CSV = "./domain_expert_phase2_top10_predictions_full.csv"
df_test_preds.to_csv(OUT_CSV, index=False)
print(f"‚úÖ CSV sauvegard√© : {OUT_CSV}")

# ============================================
# Pr√©parer labels num√©riques
# ============================================
y_true = y_test[:len(top1_preds)]
y_pred = le.transform(top1_preds)

# ============================================
# M√©triques globales
# ============================================
accuracy = accuracy_score(y_true, y_pred)

p_macro, r_macro, f1_macro, _ = precision_recall_fscore_support(
    y_true, y_pred, average="macro", zero_division=0
)

p_weighted, r_weighted, f1_weighted, _ = precision_recall_fscore_support(
    y_true, y_pred, average="weighted", zero_division=0
)

print("\n===== METRICS (Top-1) =====")
print(f"Accuracy           : {accuracy:.4f}")
print(f"Macro Precision    : {p_macro:.4f}")
print(f"Macro Recall       : {r_macro:.4f}")
print(f"Macro F1           : {f1_macro:.4f}")
print(f"Weighted Precision : {p_weighted:.4f}")
print(f"Weighted Recall    : {r_weighted:.4f}")
print(f"Weighted F1        : {f1_weighted:.4f}")

# ============================================
# Classification report (par classe)
# ============================================
report = classification_report(
    y_true,
    y_pred,
    target_names=le.classes_,
    zero_division=0
)

with open("classification_report_phase2.txt", "w") as f:
    f.write(report)

print("‚úÖ Classification report sauvegard√©")

# ============================================
# Top-10 Accuracy
# ============================================
top10_correct = 0

for true_label, top10 in zip(le.inverse_transform(y_true), top10_preds):
    if true_label in top10:
        top10_correct += 1

top10_accuracy = top10_correct / len(y_true)
print(f"\nTop-10 Accuracy : {top10_accuracy:.4f}")

# ============================================
# Matrice de confusion (classes fr√©quentes)
# ============================================
MIN_SAMPLES = 50

unique_labels, counts = np.unique(y_true, return_counts=True)
frequent_classes = unique_labels[counts >= MIN_SAMPLES]

mask = np.isin(y_true, frequent_classes)

cm = confusion_matrix(
    y_true[mask],
    y_pred[mask],
    labels=frequent_classes
)

labels_names = le.inverse_transform(frequent_classes)

plt.figure(figsize=(16, 16))
sns.heatmap(
    cm,
    xticklabels=labels_names,
    yticklabels=labels_names,
    cmap="Blues",
    fmt="d"
)
plt.title(f"Confusion Matrix ‚Äì Classes ‚â• {MIN_SAMPLES} samples")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.tight_layout()
plt.show()

print("‚úÖ Matrice de confusion affich√©e")

"""‚úÖ Best Phase2 model charg√©
Predictions Top1/Top10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [04:07<00:00,  1.21it/s]
‚úÖ CSV sauvegard√© : ./domain_expert_phase2_top10_predictions_full.csv

===== METRICS (Top-1) =====
Accuracy           : 0.8491
Macro Precision    : 0.8339
Macro Recall       : 0.8160
Macro F1           : 0.8117
Weighted Precision : 0.8580
Weighted Recall    : 0.8491
Weighted F1        : 0.8461
‚úÖ Classification report sauvegard√©

Top-10 Accuracy : 0.9743

‚úÖ Matrice de confusion affich√©e
"""

